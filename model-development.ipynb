{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport librosa\nimport librosa.display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-26T13:34:34.998204Z","iopub.execute_input":"2023-06-26T13:34:34.998620Z","iopub.status.idle":"2023-06-26T13:34:35.617977Z","shell.execute_reply.started":"2023-06-26T13:34:34.998591Z","shell.execute_reply":"2023-06-26T13:34:35.617028Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Install VGGish Model","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade numpy==1.21.6 resampy==0.2.2 tensorflow==2.8.2 tf_slim==1.1.0 six soundfile\n!git clone https://github.com/tensorflow/models.git\n# Grab the VGGish model\n!curl -O https://storage.googleapis.com/audioset/vggish_model.ckpt\n!curl -O https://storage.googleapis.com/audioset/vggish_pca_params.npz   \n# Copy the source files to the current directory.\n!cp models/research/audioset/vggish/* /kaggle/working/\n!rm -rf models","metadata":{"execution":{"iopub.status.busy":"2023-06-26T13:34:35.623916Z","iopub.execute_input":"2023-06-26T13:34:35.624261Z","iopub.status.idle":"2023-06-26T13:35:24.349649Z","shell.execute_reply.started":"2023-06-26T13:34:35.624227Z","shell.execute_reply":"2023-06-26T13:35:24.348264Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy==1.21.6 in /opt/conda/lib/python3.10/site-packages (1.21.6)\nRequirement already satisfied: resampy==0.2.2 in /opt/conda/lib/python3.10/site-packages (0.2.2)\nRequirement already satisfied: tensorflow==2.8.2 in /opt/conda/lib/python3.10/site-packages (2.8.2)\nRequirement already satisfied: tf_slim==1.1.0 in /opt/conda/lib/python3.10/site-packages (1.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (1.16.0)\nRequirement already satisfied: soundfile in /opt/conda/lib/python3.10/site-packages (0.12.1)\nRequirement already satisfied: scipy>=0.13 in /opt/conda/lib/python3.10/site-packages (from resampy==0.2.2) (1.10.1)\nRequirement already satisfied: numba>=0.32 in /opt/conda/lib/python3.10/site-packages (from resampy==0.2.2) (0.57.0)\nRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.6.3)\nRequirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (23.3.3)\nRequirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (3.8.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.1.2)\nRequirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (16.0.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (3.3.0)\nRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (3.19.6)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (59.8.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (2.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (4.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.14.1)\nRequirement already satisfied: tensorboard<2.9,>=2.8 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (2.8.0)\nRequirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (2.8.0)\nRequirement already satisfied: keras<2.9,>=2.8.0rc0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (2.8.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (0.31.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.2) (1.51.1)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile) (1.15.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.8.2) (0.40.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.21)\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.32->resampy==0.2.2) (0.40.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.17.3)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.4.6)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.28.2)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.8.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.3.6)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.2.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCloning into 'models'...\nremote: Enumerating objects: 86202, done.\u001b[K\nremote: Counting objects: 100% (1801/1801), done.\u001b[K\nremote: Compressing objects: 100% (759/759), done.\u001b[K\nremote: Total 86202 (delta 1156), reused 1634 (delta 1023), pack-reused 84401\u001b[K\nReceiving objects: 100% (86202/86202), 598.86 MiB | 26.45 MiB/s, done.\nResolving deltas: 100% (61649/61649), done.\ncurl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  277M  100  277M    0     0   214M      0  0:00:01  0:00:01 --:--:--  214M\ncurl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 73020  100 73020    0     0  1249k      0 --:--:-- --:--:-- --:--:-- 1273k\n","output_type":"stream"}]},{"cell_type":"code","source":"# Run the test, which also loads all the necessary functions.\nfrom vggish_smoke_test import *","metadata":{"execution":{"iopub.status.busy":"2023-06-26T13:35:24.351388Z","iopub.execute_input":"2023-06-26T13:35:24.351771Z","iopub.status.idle":"2023-06-26T13:35:33.702979Z","shell.execute_reply.started":"2023-06-26T13:35:24.351730Z","shell.execute_reply":"2023-06-26T13:35:33.701643Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\nTesting your install of VGGish\n\nLog Mel Spectrogram example:  [[-4.47303259 -4.29463765 -4.14939193 ... -3.97474254 -3.94778045\n  -3.78685566]\n [-4.48592983 -4.28831745 -4.13994942 ... -3.98374974 -3.94981089\n  -3.79512755]\n [-4.46165595 -4.29335712 -4.14907932 ... -3.96438562 -3.9489109\n  -3.78621325]\n ...\n [-4.46165595 -4.29335712 -4.14907932 ... -3.96438562 -3.9489109\n  -3.78621325]\n [-4.46165595 -4.29335712 -4.14907932 ... -3.96438562 -3.9489109\n  -3.78621325]\n [-4.46165595 -4.29335712 -4.14907932 ... -3.96438562 -3.9489109\n  -3.78621325]]\nVGGish embedding:  [-0.43252096 -0.25330514 -0.03891924 -0.16376    -0.34991813 -0.5993693\n -0.05658102  0.16280255 -0.75551754 -0.08260241 -0.03138599 -0.8314715\n -0.10581703 -0.01420267 -0.11077996 -0.06599088 -0.22666308  0.8060125\n -0.56459844 -0.07349288 -0.06056745 -0.11864144 -0.2629044  -0.4155161\n -0.02423218  0.36676204  0.03564969 -0.5499773  -0.00279096 -0.28981668\n -0.5713452   0.381078    0.13668716  0.91885793  0.8064256  -0.05767338\n -0.13229552 -0.05044467 -0.22702812  0.04124306  0.70887053 -0.72661525\n  0.49566716  0.24034077  0.21580261  0.88386     1.1954072   0.6688213\n  0.2091962   0.01531452  0.174491   -0.6544128  -0.15787993  0.25017855\n -0.26469582 -0.39899978  0.1458847  -0.18502574  0.39927042  0.30416963\n  0.12948173 -0.1122096  -0.40236872 -0.5374398  -0.36152235 -0.21291587\n  0.53718126 -0.30606037 -0.08813701  0.04871751  0.42514476  0.18669161\n -0.17835395 -0.0693138   0.14701045 -0.27585846 -0.257665    0.697773\n  0.45499632  0.051182   -0.05679145  0.01915705 -0.37350485 -0.19476911\n  0.51677597  0.5659667   0.6574932  -0.0018118  -0.01737224  0.40861207\n -0.19848642 -0.6980511  -0.26430067  0.25720695  0.23190105  0.23873898\n -0.1278467  -0.2912717  -0.43531063 -0.12760878 -0.30133814  0.26585326\n -0.30033347  0.4845317  -0.53912866 -0.3803264   0.19335581 -0.23141025\n  0.20179836 -0.01324049  0.03102869 -0.61035657 -0.71646774 -0.12141885\n -0.52067876  0.17772052  0.02538769  0.07066447 -0.01675121 -0.1934233\n -0.13498668  0.08212616 -0.07045759 -0.10655677 -0.44430858 -0.3327833\n -0.11444983 -0.25910604]\nPostprocessed VGGish embedding:  [152  67 116 137 136 122 125  76 160 193 111  13 155  83  59   1  44 110\n 166 162 162 255 255  94  47 192 119 163 182  27  23  33 153  42 153 255\n  10  57 255   2 133 164 232 186 255 134  84  75 107 255   0 255 113   0\n 169 212  85 255  43   0 255   0   1 255 180   0  46 255  26  86  49 161\n  86 255 129 121 255 167 212 174  19   0 255 175  57 255   0 255   0 103\n   0  11 220  40 255 245   0 255  49   0 255  53 215 255  84   0  49 214\n 209   0 255   0   0   9 207   0 255   0 160 232   0 255   0 129   0 255\n   0 192]\n\nLooks Good To Me!\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Generate audio embeddings using pretrained VGGISH model","metadata":{}},{"cell_type":"code","source":"%%writefile feature_extractor.py\nimport os\nimport numpy as np\nimport soundfile as sf\nimport tensorflow.compat.v1 as tf\nimport vggish_input\nimport vggish_params\nimport vggish_postprocess\nimport vggish_slim\n\nclass FeatureExtractor:\n    \n    def __init__(self, checkpoint_path, pca_params_path):\n        self.checkpoint_path = checkpoint_path\n        self.pca_params_path = pca_params_path\n        self.sess = tf.Session(graph=tf.Graph())\n        self.pproc = None\n        self.features_tensor = None\n        self.embedding_tensor = None\n\n    def load_model(self):\n        with self.sess.graph.as_default():\n            vggish_slim.define_vggish_slim(training=False)\n            vggish_slim.load_vggish_slim_checkpoint(self.sess, self.checkpoint_path)\n            self.features_tensor = self.sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n            self.embedding_tensor = self.sess.graph.get_tensor_by_name(vggish_params.OUTPUT_TENSOR_NAME)\n            self.pproc = vggish_postprocess.Postprocessor(self.pca_params_path)\n\n    def extract_features(self, waveform):\n        examples = vggish_input.waveform_to_examples(waveform, vggish_params.SAMPLE_RATE)\n        [embedding_batch] = self.sess.run([self.embedding_tensor],\n                                          feed_dict={self.features_tensor: examples})\n        postprocessed_batch = self.pproc.postprocess(embedding_batch)\n        return postprocessed_batch\n\n    def audio_embeddings_generator(self, audio_folder, samples_per_folder=100):\n        audio_files = []\n        labels = []\n\n        for folder_name in os.listdir(audio_folder):\n            folder_path = os.path.join(audio_folder, folder_name)\n            if os.path.isdir(folder_path):\n                audio_files_in_folder = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.mp3')]\n                audio_files_in_folder = audio_files_in_folder[:samples_per_folder]\n                audio_files.extend(audio_files_in_folder)\n                labels.extend([self.extract_label_from_audio_file(file) for file in audio_files_in_folder])\n\n        batch_embeddings = []\n        batch_labels = []\n        for audio_file, label in zip(audio_files, labels):\n            waveform, _ = sf.read(audio_file)\n            waveform = np.asarray(waveform)\n            embedding = self.extract_features(waveform)\n            batch_embeddings.append(embedding)\n            batch_labels.append(label)\n            if len(batch_embeddings) == samples_per_folder:\n                yield np.array(batch_embeddings), np.array(batch_labels)\n                batch_embeddings = []\n                batch_labels = []\n\n        if batch_embeddings:\n            yield np.array(batch_embeddings), np.array(batch_labels)\n\n    @staticmethod\n    def extract_label_from_audio_file(audio_file):\n        label = os.path.basename(os.path.dirname(audio_file))\n        return label\n","metadata":{"execution":{"iopub.status.busy":"2023-06-26T13:35:33.706559Z","iopub.execute_input":"2023-06-26T13:35:33.706946Z","iopub.status.idle":"2023-06-26T13:35:33.717265Z","shell.execute_reply.started":"2023-06-26T13:35:33.706910Z","shell.execute_reply":"2023-06-26T13:35:33.716073Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Overwriting feature_extractor.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile main.py\nimport csv\nimport numpy as np\nimport soundfile as sf\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport tqdm\nimport tensorflow.compat.v1 as tf\nfrom feature_extractor import FeatureExtractor\n\n# Define the necessary flags\ntf.compat.v1.flags.DEFINE_string('audio_folder', '/kaggle/input/audio-dataset-with-10-indian-languages/Language Detection Dataset', 'Path to the folder containing audio samples')\ntf.compat.v1.flags.DEFINE_string('checkpoint', '/kaggle/working/vggish_model.ckpt', 'Path to the VGGish checkpoint file')\ntf.compat.v1.flags.DEFINE_string('pca_params', '/kaggle/working/vggish_pca_params.npz', 'Path to the VGGish PCA parameters file')\ntf.compat.v1.flags.DEFINE_integer('samples_per_folder', 100, 'Number of samples to include per folder')\n\nFLAGS = tf.compat.v1.flags.FLAGS\n\n\ndef main(_):\n    feature_extractor = FeatureExtractor(FLAGS.checkpoint, FLAGS.pca_params)\n    feature_extractor.load_model()\n\n    embeddings = []\n    labels = []\n    progress_bar = tqdm.tqdm(feature_extractor.audio_embeddings_generator(FLAGS.audio_folder, FLAGS.samples_per_folder), desc='Extracting embeddings')\n    for batch_embeddings, batch_labels in progress_bar:\n        embeddings.append(batch_embeddings)\n        labels.append(batch_labels)\n\n    embeddings = np.concatenate(embeddings, axis=0)\n    labels = np.concatenate(labels, axis=0)\n\n    print('Embeddings shape:', embeddings.shape)\n    print('Labels shape:', labels.shape)\n\n    # Train models\n\n\nif __name__ == '__main__':\n    tf.compat.v1.app.run(main)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-26T13:35:33.719148Z","iopub.execute_input":"2023-06-26T13:35:33.720038Z","iopub.status.idle":"2023-06-26T13:35:33.734507Z","shell.execute_reply.started":"2023-06-26T13:35:33.719996Z","shell.execute_reply":"2023-06-26T13:35:33.733295Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Overwriting main.py\n","output_type":"stream"}]},{"cell_type":"code","source":"\n%timeit\n!python main.py","metadata":{"execution":{"iopub.status.busy":"2023-06-26T13:35:33.736518Z","iopub.execute_input":"2023-06-26T13:35:33.737247Z","iopub.status.idle":"2023-06-26T13:35:53.277374Z","shell.execute_reply.started":"2023-06-26T13:35:33.737211Z","shell.execute_reply":"2023-06-26T13:35:53.276000Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n  warnings.warn('`layer.apply` is deprecated and '\n/opt/conda/lib/python3.10/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:332: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n  warnings.warn('`tf.layers.flatten` is deprecated and '\nI0626 13:35:41.128499 134144635717440 saver.py:1395] Restoring parameters from /kaggle/working/vggish_model.ckpt\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n    return fn(*args)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_26_vggish_load_pretrained/RestoreV2;0:0\n\t [[{{node vggish_load_pretrained/RestoreV2/_21}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[vggish_load_pretrained/RestoreV2/_28]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_26_vggish_load_pretrained/RestoreV2;0:0\n\t [[{{node vggish_load_pretrained/RestoreV2/_21}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/kaggle/working/main.py\", line 39, in <module>\n    tf.compat.v1.app.run(main)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/platform/app.py\", line 36, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/opt/conda/lib/python3.10/site-packages/absl/app.py\", line 308, in run\n    _run_main(main, args)\n  File \"/opt/conda/lib/python3.10/site-packages/absl/app.py\", line 254, in _run_main\n    sys.exit(main(argv))\n  File \"/kaggle/working/main.py\", line 20, in main\n    feature_extractor.load_model()\n  File \"/kaggle/working/feature_extractor.py\", line 23, in load_model\n    vggish_slim.load_vggish_slim_checkpoint(self.sess, self.checkpoint_path)\n  File \"/kaggle/working/vggish_slim.py\", line 136, in load_vggish_slim_checkpoint\n    saver.restore(session, checkpoint_path)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/training/saver.py\", line 1400, in restore\n    sess.run(self.saver_def.restore_op_name,\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py\", line 967, in run\n    result = self._run(None, fetches, feed_dict, options_ptr,\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n    results = self._do_run(handle, final_targets, final_fetches,\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n    return self._do_call(_run_fn, feeds, fetches, targets, options,\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py\", line 1396, in _do_call\n    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_26_vggish_load_pretrained/RestoreV2;0:0\n\t [[{{node vggish_load_pretrained/RestoreV2/_21}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[vggish_load_pretrained/RestoreV2/_28]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_26_vggish_load_pretrained/RestoreV2;0:0\n\t [[{{node vggish_load_pretrained/RestoreV2/_21}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored.\n","output_type":"stream"}]}]}